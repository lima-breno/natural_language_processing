{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lima-breno/natural_language_processing/blob/main/Lista2_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LISTA DE EXERCÍCIOS 02\n"
      ],
      "metadata": {
        "id": "xLynux-fOakb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando bibliotecas"
      ],
      "metadata": {
        "id": "1YjguOTFOfDX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J1x-sg8Cc3j",
        "outputId": "b97658c2-b78e-4a72-9c81-ac26eb3f423a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package machado to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import machado\n",
        "nltk.download('machado')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definindo base de dados"
      ],
      "metadata": {
        "id": "UoEm2ieUOjPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contos = []\n",
        "for k in range(1,9):\n",
        "  contos.extend(machado.sents(f'romance/marm0{k}.txt'))"
      ],
      "metadata": {
        "id": "l9Re6Yl7Dfov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords = stopwords.words('portuguese')\n",
        "\n",
        "def pre_processamento(sentenca):\n",
        "  sentenca = [token for token in sentenca if token not in punctuation]\n",
        "  sentenca = [token.lower() for token in sentenca]\n",
        "  sentenca = [re.sub(r'\\d', '', token) for token in sentenca]\n",
        "  sentenca = [token for token in sentenca if token not in stopwords]\n",
        "  return sentenca\n",
        "\n",
        "machado_memorias = [pre_processamento(sentenca) for sentenca in contos]"
      ],
      "metadata": {
        "id": "EepC01WMEU5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercícios"
      ],
      "metadata": {
        "id": "Cb9xdlgpOoVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercício 01\n",
        "Construa três modelos de embedding variando apenas o número de epochs nos valores: 5, 10 e 20. Use os seguintes parâmetros fixos para todos os modelos:\n",
        "\n",
        "window = 3\n",
        "\n",
        "sg = 0\n",
        "\n",
        "min_count = 3\n",
        "\n",
        "vector_size = 100"
      ],
      "metadata": {
        "id": "Qw7-BbOhOqAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Lista de valores de epochs que serão testados\n",
        "valores_de_epochs = [5, 10, 20]\n",
        "\n",
        "# Parâmetros fixos\n",
        "params_fixos = {\n",
        "    \"vector_size\": 100,\n",
        "    \"window\": 3,\n",
        "    \"sg\": 0,\n",
        "    \"min_count\": 3\n",
        "}\n",
        "\n",
        "# Dicionário para armazenar os modelos\n",
        "modelos = {}\n",
        "\n",
        "# Treinamento dos modelos\n",
        "for ep in valores_de_epochs:\n",
        "    print(f\"Treinando modelo com {ep} epochs...\")\n",
        "    modelo = Word2Vec(\n",
        "        sentences=machado_memorias,\n",
        "        epochs=ep,\n",
        "        **params_fixos\n",
        "    )\n",
        "    modelos[f\"modelo_{ep}ep\"] = modelo\n",
        "    print(f\"Modelo com {ep} epochs treinado com sucesso!\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhK5itCyQhcw",
        "outputId": "ac1a161b-c78a-4753-baea-c6095238787f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando modelo com 5 epochs...\n",
            "Modelo com 5 epochs treinado com sucesso!\n",
            "\n",
            "Treinando modelo com 10 epochs...\n",
            "Modelo com 10 epochs treinado com sucesso!\n",
            "\n",
            "Treinando modelo com 20 epochs...\n",
            "Modelo com 20 epochs treinado com sucesso!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício 02\n",
        "\n",
        "Para cada modelo, obtenha as 5 palavras mais similares às seguintes palavras:\n",
        "\n",
        "\n",
        "*  amor\n",
        "*  paixão\n",
        "*  memória\n",
        "*  relógio\n"
      ],
      "metadata": {
        "id": "vSQloH-GO0Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de palavras que queremos analisar\n",
        "palavras_alvo = [\"amor\", \"paixão\", \"memória\", \"relógio\"]\n",
        "\n",
        "# Para cada modelo treinado (com 5, 10 e 20 epochs)\n",
        "for nome_modelo, modelo in modelos.items():\n",
        "    print(f\"\\n Resultados para o {nome_modelo}:\\n\")\n",
        "\n",
        "    # Para cada palavra da lista\n",
        "    for palavra in palavras_alvo:\n",
        "        print(f\"Palavras parecidas com '{palavra}':\")\n",
        "\n",
        "        # Verifica se a palavra existe no vocabulário do modelo\n",
        "        if palavra in modelo.wv:\n",
        "            similares = modelo.wv.most_similar(palavra, topn=5)\n",
        "            for sim_palavra, score in similares:\n",
        "                print(f\"  {sim_palavra}  →  similaridade: {score:.2f}\")\n",
        "        else:\n",
        "            print(f\"  (A palavra '{palavra}' não foi encontrada no vocabulário.)\")\n",
        "\n",
        "        print()  # Linha em branco para separar os resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqZiVkAsQ0C1",
        "outputId": "fc6e521d-9e1a-4667-871b-84be92c49362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Resultados para o modelo_5ep:\n",
            "\n",
            "Palavras parecidas com 'amor':\n",
            "  verdade  →  similaridade: 1.00\n",
            "  poderia  →  similaridade: 1.00\n",
            "  homem  →  similaridade: 1.00\n",
            "  tudo  →  similaridade: 1.00\n",
            "  agora  →  similaridade: 1.00\n",
            "\n",
            "Palavras parecidas com 'paixão':\n",
            "  vista  →  similaridade: 1.00\n",
            "  leitor  →  similaridade: 1.00\n",
            "  aí  →  similaridade: 1.00\n",
            "  confiança  →  similaridade: 1.00\n",
            "  criança  →  similaridade: 1.00\n",
            "\n",
            "Palavras parecidas com 'memória':\n",
            "  bela  →  similaridade: 1.00\n",
            "  acaso  →  similaridade: 1.00\n",
            "  flor  →  similaridade: 1.00\n",
            "  alegria  →  similaridade: 1.00\n",
            "  passado  →  similaridade: 1.00\n",
            "\n",
            "Palavras parecidas com 'relógio':\n",
            "  primeiras  →  similaridade: 1.00\n",
            "  trabalho  →  similaridade: 1.00\n",
            "  sol  →  similaridade: 1.00\n",
            "  umas  →  similaridade: 1.00\n",
            "  caminho  →  similaridade: 1.00\n",
            "\n",
            "\n",
            " Resultados para o modelo_10ep:\n",
            "\n",
            "Palavras parecidas com 'amor':\n",
            "  sentimento  →  similaridade: 0.95\n",
            "  natureza  →  similaridade: 0.95\n",
            "  tal  →  similaridade: 0.94\n",
            "  porque  →  similaridade: 0.94\n",
            "  maior  →  similaridade: 0.94\n",
            "\n",
            "Palavras parecidas com 'paixão':\n",
            "  confiança  →  similaridade: 0.98\n",
            "  criatura  →  similaridade: 0.98\n",
            "  afeição  →  similaridade: 0.98\n",
            "  enfático  →  similaridade: 0.98\n",
            "  cautela  →  similaridade: 0.98\n",
            "\n",
            "Palavras parecidas com 'memória':\n",
            "  comum  →  similaridade: 0.99\n",
            "  infeliz  →  similaridade: 0.99\n",
            "  sociais  →  similaridade: 0.99\n",
            "  resultado  →  similaridade: 0.99\n",
            "  método  →  similaridade: 0.99\n",
            "\n",
            "Palavras parecidas com 'relógio':\n",
            "  café  →  similaridade: 0.99\n",
            "  donde  →  similaridade: 0.99\n",
            "  préstito  →  similaridade: 0.99\n",
            "  leito  →  similaridade: 0.99\n",
            "  alto  →  similaridade: 0.99\n",
            "\n",
            "\n",
            " Resultados para o modelo_20ep:\n",
            "\n",
            "Palavras parecidas com 'amor':\n",
            "  sentimento  →  similaridade: 0.79\n",
            "  pura  →  similaridade: 0.76\n",
            "  amava  →  similaridade: 0.72\n",
            "  admiração  →  similaridade: 0.71\n",
            "  vaidade  →  similaridade: 0.71\n",
            "\n",
            "Palavras parecidas com 'paixão':\n",
            "  afeição  →  similaridade: 0.83\n",
            "  dura  →  similaridade: 0.83\n",
            "  ambição  →  similaridade: 0.83\n",
            "  confiança  →  similaridade: 0.82\n",
            "  abstenção  →  similaridade: 0.81\n",
            "\n",
            "Palavras parecidas com 'memória':\n",
            "  resultado  →  similaridade: 0.81\n",
            "  exclusivo  →  similaridade: 0.80\n",
            "  responsabilidade  →  similaridade: 0.79\n",
            "  mocidade  →  similaridade: 0.79\n",
            "  mistura  →  similaridade: 0.78\n",
            "\n",
            "Palavras parecidas com 'relógio':\n",
            "  xícara  →  similaridade: 0.90\n",
            "  café  →  similaridade: 0.90\n",
            "  terraço  →  similaridade: 0.86\n",
            "  selim  →  similaridade: 0.86\n",
            "  oposta  →  similaridade: 0.86\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício 03"
      ],
      "metadata": {
        "id": "Au5Wt4cjO7LS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quais diferenças você observou nas palavras mais similares conforme o número de epochs aumentou?**\n",
        "\n",
        "À medida que o número de epochs aumenta, nota-se uma mudança significativa tanto nos valores de similaridade quanto na qualidade das palavras mais próximas:\n",
        "\n",
        "Com 5 epochs:\n",
        "\n",
        "Todas as palavras similares apresentam similaridade máxima (1.00), o que é atípico e sugere que o modelo ainda não capturou relações semânticas reais.\n",
        "\n",
        "As palavras retornadas, em muitos casos, não têm relação semântica clara com as palavras-alvo (ex: \"amor\" = \"verdade\", \"poderia\", \"homem\", \"tudo\", \"agora\").\n",
        "\n",
        "Com 10 epochs:\n",
        "\n",
        "Os valores de similaridade diminuem levemente (em torno de 0.94 a 0.99), indicando que o modelo começa a diferenciar melhor as relações.\n",
        "\n",
        "As palavras similares tornam-se mais relevantes semanticamente (ex: \"amor\" = \"sentimento\", \"natureza\"; \"paixão\" = \"afeição\", \"confiança\").\n",
        "\n",
        "Com 20 epochs:\n",
        "\n",
        "A similaridade diminui ainda mais (0.71 a 0.90), sugerindo maior refinamento dos vetores.\n",
        "\n",
        "As palavras próximas são, em sua maioria, semanticamente relacionadas às palavras-alvo (ex: \"amor\" = \"sentimento\", \"pura\", \"amava\"; \"paixão\" = \"afeição\", \"ambição\", \"confiança\")."
      ],
      "metadata": {
        "id": "eYYLwy5KeaCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Algum dos modelos produziu resultados mais coerentes ou interessantes? Justifique.**\n",
        "\n",
        "O modelo com 20 épocas apresenta resultados ainda mais refinados, com associações que demonstram compreensão semântica mais profunda (ex: \"amor\" = \"amava\", \"admiração\", \"vaidade\"; \"memória\" = \"responsabilidade\", \"mocidade\", \"mistura\").\n",
        "As palavras similares são mais específicas e contextualizadas, o que pode ser considerado mais interessante para análises literárias."
      ],
      "metadata": {
        "id": "-O7db6YtPLCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Com base nas análises, qual valor de epoch pareceu mais apropriado para este conjunto de dados?**\n",
        "\n",
        "O valor de 20 epochs parece ser o mais apropriado para este conjunto de dados, pois produz resultados mais coerentes, específicos e semanticamente interessantes, refletindo melhor as nuances do texto literário analisado. Isso é especialmente desejável em tarefas de análise textual onde a riqueza semântica é fundamental."
      ],
      "metadata": {
        "id": "SpoSpACsPNFR"
      }
    }
  ]
}